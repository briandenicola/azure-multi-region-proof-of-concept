# Overview 
These notebooks attempt to display the entropy of the AES keys created by the CQRS application
The first Spark notebook that streams the AES Keys generated by the application from Event Hub into Azure DataLake Gen 2 (ADLS) in Parquet format. 
The second notebook takes the parquet files and generates a graph of the distriubtion of the bytes that make up all the AES keys generated so far

# Setup

## Azure Resource Creation
* cd ..\..\Infrastructure\Databricks
* New-AzResourceGroup -Name {Resource Group} -l {region}
* New-AzResourceGroupDeployment -Name databricks -TemplateParameterFile .\azuredeploy.parameters.json -TemplateFile .\azuredeploy.json  -ResourceGroupName {Resource Group} -Verbose
* .\create_event_hub_consumer_group.sh -n {App Name} -g {Resource Group} -r {region} [-r {secondary region}
    * Application Name should be taken from the output of .\create_infrastructure.sh script run earlier 
    * The script will output the Event Hub Namespace Primary Connection String which will be used to setup a databricks secret below 

### Azure AD SPN Configuration 
* $botPass = New-Password -Length 25 -ExcludeSpecialCharacters (Function from bjd.Common.Functions)
* $credentials = New-Object Microsoft.Azure.Commands.ActiveDirectory.PSADPasswordCredential -Property @{StartDate=Get-Date; EndDate=Get-Date -Year 2024; Password=$botPass}
* $sp = New-AzAdServicePrincipal -DisplayName bjdCQRSDatabricks -PasswordCredential $credentials
* New-AzRoleAssignment -ApplicationId $sp.ApplicationId -RoleDefinitionName "Storage Blob Data Owner" -ResourceGroupName {Resource Group}
* $tenantId = ("https://login.microsoftonline.com/{0}/oauth2/token" -f (Get-AzContext).Tenant.Id)

## Databaricks Configuration

### Cli Installation
* pip install databricks-cli

## Secrets Setup 
* Create a PAN token within Azure Databricks
    * https://docs.microsoft.com/en-us/azure/databricks/dev-tools/api/latest/authentication#--generate-a-personal-access-token
* databricks configure 
* databricks secrets create-scope --scope entropy-demo
* databricks secrets write --scope entropy-demo --key client-id --string-value $sp.ApplicationId
* databricks secrets write --scope entropy-demo --key client-secret --string-value $botPass
* databricks secrets write --scope entropy-demo --key client-tenant --string-value $tenantId
* databricks secrets write --scope entropy-demo --key eventhub-connnection-string --string-value {Event Hub ConnectionString}

## Cluster Library
* Requires - com.microsoft.azure:azure-eventhubs-spark_2.11:2.3.12 (https://github.com/Azure/azure-event-hubs-spark/)
    * Install using Maven into the cluster

## Notebook Deployment
* databricks workspace import -l python ../../Source/notebooks/caculate-entropy.py /Shared/calculate-entropy.py
* databricks workspace import -l python ../../Source/notebooks/eventhub-stream-reader.py /Shared/eventhub-stream-reader.py
* databricks workspace import -l python ../../Source/notebooks/stream-to-delta-table.py /Shared/stream-to-delta-table.py